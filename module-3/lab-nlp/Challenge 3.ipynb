{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El lab lo he hecho con una muestra de 500 porque con 20000 me acab√≥ petando el ordenador y tuve que reiniciarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweer_data = pd.read_csv('./Sentiment140.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(s):\n",
    "    s = re.sub(r'https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', '', s)\n",
    "    s = re.sub('[^a-zA-Z_]+', ' ', s)\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "def tokenize(s):\n",
    "    return word_tokenize(s)\n",
    "\n",
    "def stem_and_lemmatize(l):\n",
    "    result = []\n",
    "    for i in l:\n",
    "        sno = nltk.stem.SnowballStemmer('english')\n",
    "        x = sno.stem(i)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        x = lemmatizer.lemmatize(x)\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    stop_words = get_stop_words('en')\n",
    "    filtered_words = [word for word in l if word not in stop_words]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tweer_data.sample(n=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['text_processed'] = sample['text'].apply(clean_up)\n",
    "sample['text_processed'] = sample['text_processed'].apply(tokenize)\n",
    "sample['text_processed'] = sample['text_processed'].apply(stem_and_lemmatize)\n",
    "sample['text_processed'] = sample['text_processed'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514293</th>\n",
       "      <td>0</td>\n",
       "      <td>2190584004</td>\n",
       "      <td>Tue Jun 16 03:08:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Vicki_Gee</td>\n",
       "      <td>i miss nikki nu nu already  shes always there ...</td>\n",
       "      <td>[miss, nikki, nu, nu, alreadi, shes, alway, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142282</th>\n",
       "      <td>0</td>\n",
       "      <td>1881451988</td>\n",
       "      <td>Fri May 22 04:42:15 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PatCashin</td>\n",
       "      <td>So I had a dream last night. I  remember a sig...</td>\n",
       "      <td>[dream, last, night, rememb, sign, clear, told...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403727</th>\n",
       "      <td>0</td>\n",
       "      <td>2058252964</td>\n",
       "      <td>Sat Jun 06 14:34:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>deelectable</td>\n",
       "      <td>@girlyghost ohh poor sickly you   (((hugs)) ho...</td>\n",
       "      <td>[girlyghost, ohh, poor, sick, hug, hope, feel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649503</th>\n",
       "      <td>0</td>\n",
       "      <td>2237307600</td>\n",
       "      <td>Fri Jun 19 05:34:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>justinekepa</td>\n",
       "      <td>it is raining again</td>\n",
       "      <td>[rain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610789</th>\n",
       "      <td>0</td>\n",
       "      <td>2224301193</td>\n",
       "      <td>Thu Jun 18 09:20:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cmatt007</td>\n",
       "      <td>@MissKeriBaby wish I was in LA right now</td>\n",
       "      <td>[misskeribabi, wish, wa, la, right, now]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target          id                          date      flag  \\\n",
       "514293       0  2190584004  Tue Jun 16 03:08:48 PDT 2009  NO_QUERY   \n",
       "142282       0  1881451988  Fri May 22 04:42:15 PDT 2009  NO_QUERY   \n",
       "403727       0  2058252964  Sat Jun 06 14:34:17 PDT 2009  NO_QUERY   \n",
       "649503       0  2237307600  Fri Jun 19 05:34:22 PDT 2009  NO_QUERY   \n",
       "610789       0  2224301193  Thu Jun 18 09:20:06 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \\\n",
       "514293    Vicki_Gee  i miss nikki nu nu already  shes always there ...   \n",
       "142282    PatCashin  So I had a dream last night. I  remember a sig...   \n",
       "403727  deelectable  @girlyghost ohh poor sickly you   (((hugs)) ho...   \n",
       "649503  justinekepa                               it is raining again    \n",
       "610789     cmatt007          @MissKeriBaby wish I was in LA right now    \n",
       "\n",
       "                                           text_processed  \n",
       "514293  [miss, nikki, nu, nu, alreadi, shes, alway, ne...  \n",
       "142282  [dream, last, night, rememb, sign, clear, told...  \n",
       "403727  [girlyghost, ohh, poor, sick, hug, hope, feel,...  \n",
       "649503                                             [rain]  \n",
       "610789           [misskeribabi, wish, wa, la, right, now]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miss', 'nikki', 'nu', 'nu', 'alreadi', 'shes', 'alway', 'need', 'thank', 'u']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for x in sample.text_processed:\n",
    "    words += x\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(words)\n",
    "top_words = sorted(fdist, key=fdist.get, reverse=True)[:5000]\n",
    "\n",
    "# fdist = FreqDist(lista)\n",
    "# voc = fdist.most_common(5000)\n",
    "# top = [x[0] for x in voc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in top_words:\n",
    "        features[w] = (w in words)\n",
    "    sentiment = SentimentIntensityAnalyzer().polarity_scores(\" \".join(document))\n",
    "    if sentiment[\"pos\"] > 0.2:\n",
    "        sentiment = True\n",
    "    else:\n",
    "        sentiment = False\n",
    "    return (features, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_in_text = sample['text_processed'].apply(find_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = features_in_text[:400], features_in_text[400:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    love = True             True : False  =     18.2 : 1.0\n",
      "                     lol = True             True : False  =      8.1 : 1.0\n",
      "                    good = True             True : False  =      6.9 : 1.0\n",
      "                    like = True             True : False  =      6.4 : 1.0\n",
      "                    look = True             True : False  =      5.5 : 1.0\n",
      "                   watch = True            False : True   =      4.5 : 1.0\n",
      "                    next = True            False : True   =      3.9 : 1.0\n",
      "                       p = True             True : False  =      3.8 : 1.0\n",
      "                   alway = True             True : False  =      3.8 : 1.0\n",
      "                  wonder = True             True : False  =      3.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 67.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
